{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93064985-eecd-4577-b559-523e5a2ee766",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Python Read Files\n",
    "\n",
    "- We have the following file, located in the same below folder:\n",
    " - /databricks/driver/demofile.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "899b386b-866c-47df-820c-517d7870db14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Rohish Zade.\nI'm a Data Engineer. \nI work in MNC.\nI work on Azure Cloud\n"
     ]
    }
   ],
   "source": [
    "f = open(\"/databricks/driver/rohish/demofile.txt\", \"r\")\n",
    "print(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "068bfa34-0b0c-47fa-bf7f-9485229e7292",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Rohish \n"
     ]
    }
   ],
   "source": [
    "# Read Only Parts of the File\n",
    "# By default the read() method returns the whole text, but you can also specify how many characters you want to return:\n",
    "f = open(\"/databricks/driver/rohish/demofile.txt\", \"r\")\n",
    "print(f.read(18))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c90f1c7-04ad-475e-a77a-1b9f2ee15c64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Rohish Zade.\nI'm a Data Engineer. \nI work in MNC.\nI work on Azure Cloud\nExpert in ETL Migration\n"
     ]
    }
   ],
   "source": [
    "# Python code to illustrate with()\n",
    "with open(\"/databricks/driver/rohish/demofile.txt\") as file:  \n",
    "    data = file.read() \n",
    "print(data)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a13bb06c-556b-4f65-8bd7-9b3e9c9d5049",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'is', 'Rohish', 'Zade.']\n[\"I'm\", 'a', 'Data', 'Engineer.']\n['I', 'work', 'in', 'MNC.']\n['I', 'work', 'on', 'Azure', 'Cloud']\n"
     ]
    }
   ],
   "source": [
    "# Python code to illustrate split() function\n",
    "with open(\"/databricks/driver/rohish/demofile.txt\", \"r\") as file:\n",
    "    data = file.readlines()\n",
    "    for line in data:\n",
    "        word = line.split()\n",
    "        print (word)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "254cf921-7f11-4a0f-92f7-3f6aaccc818f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cb753f8-3b41-41c9-bae7-9bfaa523e2a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Python File Write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1b60a40-dd5d-4489-867d-fb7c5702e379",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#####Write to an Existing File\n",
    "To write to an existing file, you must add a parameter to the open() function:\n",
    "- \"a\" - Append - will append to the end of the file\n",
    "- \"w\" - Write - will overwrite any existing content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "013a6754-aef5-4692-af8f-0cb6475c86da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Rohish Zade.\nI'm a Data Engineer. \nI work in MNC.\nI work on Azure Cloud\nExpert in ETL Migration\n"
     ]
    }
   ],
   "source": [
    "# Open the file \"demofile.txt\" and append content to the file:\n",
    "f = open(\"/databricks/driver/rohish/demofile.txt\", \"a\")\n",
    "f.write(\"\\nExpert in ETL Migration\")\n",
    "f.close()\n",
    "\n",
    "#reading the file after the appending:\n",
    "f = open(\"/databricks/driver/rohish/demofile.txt\", \"r\")\n",
    "print(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26593f59-520d-4a25-baa8-ada35048ca8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file is overwriten! No info about Rohish\n"
     ]
    }
   ],
   "source": [
    "# Open the file overwrite the content:\n",
    "f = open(\"/databricks/driver/rohish/demofile.txt\", \"w\")\n",
    "f.write(\"The file is overwriten! No info about Rohish\")\n",
    "f.close()\n",
    "\n",
    "# reading the file after the overwriting:\n",
    "f = open(\"/databricks/driver/rohish/demofile.txt\", \"r\")\n",
    "a = f.read()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbcac9c1-5bbc-4848-af99-e97ca4b22461",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5820bde-8cce-4b62-a556-0ae1c9130a34",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#####Creating a New File\n",
    "To create a new file in Python, use the open() method, with one of the following parameters:\n",
    "- \"x\" - Create - will create a file, returns an error if the file exist\n",
    "- \"a\" - Append - will create a file if the specified file does not exist\n",
    "- \"w\" - Write - will create a file if the specified file does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cc816a5-ff1e-44d9-bb09-e3217d6faded",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mFileExistsError\u001B[0m                           Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2857216700807461>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m #  Creating a file called \"myfile.txt\":\n",
       "\u001B[1;32m      2\u001B[0m f = open(\"/databricks/driver/rohish/demofile.txt\", \"x\") #it will throw an error as file is already exist\n",
       "\u001B[1;32m      3\u001B[0m f.close()\n",
       "\n",
       "\u001B[0;31mFileExistsError\u001B[0m: [Errno 17] File exists: '/databricks/driver/rohish/demofile.txt'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mFileExistsError\u001B[0m                           Traceback (most recent call last)\nFile \u001B[0;32m<command-2857216700807461>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m #  Creating a file called \"myfile.txt\":\n\u001B[1;32m      2\u001B[0m f = open(\"/databricks/driver/rohish/demofile.txt\", \"x\") #it will throw an error as file is already exist\n\u001B[1;32m      3\u001B[0m f.close()\n\n\u001B[0;31mFileExistsError\u001B[0m: [Errno 17] File exists: '/databricks/driver/rohish/demofile.txt'",
       "errorSummary": "<span class='ansi-red-fg'>FileExistsError</span>: [Errno 17] File exists: '/databricks/driver/rohish/demofile.txt'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = open(\"/databricks/driver/rohish/demofile.txt\", \"x\") #it will throw an error as file is already exist\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff6a6e28-327e-42d3-89b7-49e697d9bed9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before creating a file:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>file:/databricks/driver/rohish/demofile.txt</td><td>demofile.txt</td><td>44</td><td>1722060374794</td></tr><tr><td>file:/databricks/driver/rohish/new_file.txt</td><td>new_file.txt</td><td>0</td><td>1722060758829</td></tr><tr><td>file:/databricks/driver/rohish/demofile1.txt</td><td>demofile1.txt</td><td>0</td><td>1722060656337</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "file:/databricks/driver/rohish/demofile.txt",
         "demofile.txt",
         44,
         1722060374794
        ],
        [
         "file:/databricks/driver/rohish/new_file.txt",
         "new_file.txt",
         0,
         1722060758829
        ],
        [
         "file:/databricks/driver/rohish/demofile1.txt",
         "demofile1.txt",
         0,
         1722060656337
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mFileExistsError\u001B[0m                           Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2857216700807462>:5\u001B[0m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# do diplay the files in directory\u001B[39;00m\n",
       "\u001B[1;32m      3\u001B[0m display(dbutils\u001B[38;5;241m.\u001B[39mfs\u001B[38;5;241m.\u001B[39mls(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile:/databricks/driver/rohish/\u001B[39m\u001B[38;5;124m\"\u001B[39m)) \u001B[38;5;66;03m# this is a spark code and will not work in python IDE's\u001B[39;00m\n",
       "\u001B[0;32m----> 5\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/databricks/driver/rohish/demofile1.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;66;03m#it will create empty file\u001B[39;00m\n",
       "\u001B[1;32m      6\u001B[0m f\u001B[38;5;241m.\u001B[39mclose()\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAfter creating a file:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "\u001B[0;31mFileExistsError\u001B[0m: [Errno 17] File exists: '/databricks/driver/rohish/demofile1.txt'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mFileExistsError\u001B[0m                           Traceback (most recent call last)\nFile \u001B[0;32m<command-2857216700807462>:5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# do diplay the files in directory\u001B[39;00m\n\u001B[1;32m      3\u001B[0m display(dbutils\u001B[38;5;241m.\u001B[39mfs\u001B[38;5;241m.\u001B[39mls(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile:/databricks/driver/rohish/\u001B[39m\u001B[38;5;124m\"\u001B[39m)) \u001B[38;5;66;03m# this is a spark code and will not work in python IDE's\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/databricks/driver/rohish/demofile1.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;66;03m#it will create empty file\u001B[39;00m\n\u001B[1;32m      6\u001B[0m f\u001B[38;5;241m.\u001B[39mclose()\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAfter creating a file:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\n\u001B[0;31mFileExistsError\u001B[0m: [Errno 17] File exists: '/databricks/driver/rohish/demofile1.txt'",
       "errorSummary": "<span class='ansi-red-fg'>FileExistsError</span>: [Errno 17] File exists: '/databricks/driver/rohish/demofile1.txt'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Before creating a file:\")\n",
    "# do diplay the files in directory\n",
    "display(dbutils.fs.ls(\"file:/databricks/driver/rohish/\")) # this is a spark code and will not work in python IDE's\n",
    "\n",
    "f = open(\"/databricks/driver/rohish/demofile1.txt\", \"x\") #it will create empty file\n",
    "f.close()\n",
    "\n",
    "print(\"After creating a file:\")\n",
    "display(dbutils.fs.ls(\"file:/databricks/driver/rohish/\"))  # this is a spark code and will not work in python IDE's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "336552e1-a406-4bad-b331-b776c14eb6ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>file:/databricks/driver/rohish/demofile.txt</td><td>demofile.txt</td><td>44</td><td>1722060374794</td></tr><tr><td>file:/databricks/driver/rohish/new_file.txt</td><td>new_file.txt</td><td>0</td><td>1722060758829</td></tr><tr><td>file:/databricks/driver/rohish/demofile1.txt</td><td>demofile1.txt</td><td>0</td><td>1722060656337</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "file:/databricks/driver/rohish/demofile.txt",
         "demofile.txt",
         44,
         1722060374794
        ],
        [
         "file:/databricks/driver/rohish/new_file.txt",
         "new_file.txt",
         0,
         1722060758829
        ],
        [
         "file:/databricks/driver/rohish/demofile1.txt",
         "demofile1.txt",
         0,
         1722060656337
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new file if it does not exist:\n",
    "f = open(\"/databricks/driver/rohish/new_file.txt\", \"x\") #it will create empty file\n",
    "f.close()\n",
    "\n",
    "\n",
    "display(dbutils.fs.ls(\"file:/databricks/driver/rohish/\"))  # this is a spark code and will not work in python IDE's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2e40107-7053-4d48-9457-9a64bbf316b5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33c46ff8-43e8-4332-aaca-1bda0968b013",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Deleting a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dcd1253-208e-4869-874b-943f28a890af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>file:/databricks/driver/rohish/demofile.txt</td><td>demofile.txt</td><td>44</td><td>1722060374794</td></tr><tr><td>file:/databricks/driver/rohish/demofile1.txt</td><td>demofile1.txt</td><td>0</td><td>1722060656337</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "file:/databricks/driver/rohish/demofile.txt",
         "demofile.txt",
         44,
         1722060374794
        ],
        [
         "file:/databricks/driver/rohish/demofile1.txt",
         "demofile1.txt",
         0,
         1722060656337
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To delete a file, you must import the OS module, and run its os.remove() function:\n",
    "import os\n",
    "os.remove(\"/databricks/driver/rohish/new_file.txt\") # new file will be deleted\n",
    "\n",
    "# do diplay the files in directory\n",
    "display(dbutils.fs.ls(\"file:/databricks/driver/rohish/\"))  # this is a spark code and will not work in python IDE's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61f27bb8-6a25-404f-92fb-e87f579b86e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d2f69c4-b93f-42eb-8124-bffedcff7f9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2857216700807471>:2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# will get error if we try do delete the which does not exists\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mremove\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/databricks/driver/rohish/new_file.txt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
       "\n",
       "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/databricks/driver/rohish/new_file.txt'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-2857216700807471>:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# will get error if we try do delete the which does not exists\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mremove\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/databricks/driver/rohish/new_file.txt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\n\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/databricks/driver/rohish/new_file.txt'",
       "errorSummary": "<span class='ansi-red-fg'>FileNotFoundError</span>: [Errno 2] No such file or directory: '/databricks/driver/rohish/new_file.txt'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# will get error if we try do delete the which does not exists\n",
    "os.remove(\"/databricks/driver/rohish/new_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab629ec2-306f-488f-b801-e21e27b7352e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file does not exist\n"
     ]
    }
   ],
   "source": [
    "# Check if File exist:\n",
    "# To avoid getting an error, you might want to check if the file exists before you try to delete it:\n",
    "\n",
    "\n",
    "# Check if file exists, then delete it:\n",
    "import os\n",
    "if os.path.exists(\"/databricks/driver/rohish/new_file.txt\"):\n",
    "    os.remove(\"/databricks/driver/rohish/new_file.txt\")\n",
    "else:\n",
    "    print(\"The file does not exist\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "file_operations",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
